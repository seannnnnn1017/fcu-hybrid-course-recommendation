import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics.pairwise import cosine_similarity
import ast
import re
from typing import Dict, List, Tuple
import warnings
from torch.utils.data import Dataset, DataLoader
from sentence_transformers import SentenceTransformer
sbert_model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
# é€™æ”¯æ¨¡å‹æ”¯æ´ä¸­è‹±æ–‡ï¼Œ768 ç¶­ï¼›ä¹Ÿå¯æ›æ›´å°çš„ all-MiniLM-L6-v2 (384 ç¶­)


warnings.filterwarnings('ignore')
class InteractionDataset(Dataset):
    """æŠŠäº’å‹•ç´€éŒ„è½‰æˆ PyTorch Dataset"""

    def __init__(self, rec_system):
        df = rec_system.interactions_df
        self.student_ids  = torch.LongTensor(df['student_idx'].values)
        self.course_ids   = torch.LongTensor(df['course_idx'].values)
        self.ratings      = torch.FloatTensor(df['rating'].values)

        # å°é½Šå°æ‡‰çš„å…§å®¹ç‰¹å¾µ
        self.student_features = torch.FloatTensor(
            rec_system.student_features[self.student_ids]
        )
        self.course_features = torch.FloatTensor(
            rec_system.course_content_features[self.course_ids]
        )

    def __len__(self):
        return len(self.ratings)

    def __getitem__(self, idx):
        return (self.student_ids[idx],
                self.course_ids[idx],
                self.student_features[idx],
                self.course_features[idx],
                self.ratings[idx])


class HybridRecommendationSystem:
    """
    åŸºæ–¼æ·±åº¦å­¸ç¿’çš„æ··åˆæ¨è–¦ç³»çµ±
    çµåˆå”åŒéæ¿¾(Collaborative Filtering)å’Œå…§å®¹éæ¿¾(Content-based Filtering)
    """
    
    def __init__(self, embedding_dim=64, hidden_dims=[128, 64, 32]):
        self.embedding_dim = embedding_dim
        self.hidden_dims = hidden_dims
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # æ•¸æ“šå­˜å„²
        self.course_data = None
        self.student_data = None
        self.interaction_matrix = None
        
        # ç‰¹å¾µç·¨ç¢¼å™¨
        self.student_encoder = LabelEncoder()
        self.course_encoder = LabelEncoder()
        self.tfidf_vectorizer = TfidfVectorizer(max_features=100, stop_words='english')
        self.scaler = StandardScaler()
        
        # æ¨¡å‹çµ„ä»¶
        self.collaborative_model = None
        self.content_model = None
        self.hybrid_model = None
        
    def load_data(self, course_file, student_file):
        """è¼‰å…¥èª²ç¨‹å’Œå­¸ç”Ÿæ•¸æ“š"""
        self.course_data = pd.read_csv(course_file)
        self.student_data = pd.read_csv(student_file)
        
        # è™•ç†å­¸ç”Ÿå·²ä¿®èª²ç¨‹åˆ—è¡¨
        self.student_data['passed_courses'] = self.student_data['passed_courses'].apply(
            lambda x: ast.literal_eval(x) if isinstance(x, str) else x
        )
        
        print(f"è¼‰å…¥èª²ç¨‹æ•¸æ“š: {len(self.course_data)} é–€èª²ç¨‹")
        print(f"è¼‰å…¥å­¸ç”Ÿæ•¸æ“š: {len(self.student_data)} åå­¸ç”Ÿ")
        
    def preprocess_data(self):
        """æ•¸æ“šé è™•ç†"""
        # 1. å‰µå»ºäº¤äº’çŸ©é™£ (å­¸ç”Ÿ-èª²ç¨‹)
        self._create_interaction_matrix()
        
        # 2. è™•ç†èª²ç¨‹å…§å®¹ç‰¹å¾µ
        self._process_course_features()
        
        # 3. è™•ç†å­¸ç”Ÿç‰¹å¾µ
        self._process_student_features()
        
        print("æ•¸æ“šé è™•ç†å®Œæˆ")
        
    def _create_interaction_matrix(self):
        """å‰µå»ºå­¸ç”Ÿ-èª²ç¨‹äº¤äº’çŸ©é™£"""
        # å±•é–‹å­¸ç”Ÿèª²ç¨‹è¨˜éŒ„
        interactions = []
        for _, student in self.student_data.iterrows():
            for course_code in student['passed_courses']:
                interactions.append({
                    'student_id': student['student_id'],
                    'course_code': course_code,
                    'rating': 1.0  # å‡è¨­å·²ä¿®èª²ç¨‹ç‚ºæ­£å‘åé¥‹
                })
        
        self.interactions_df = pd.DataFrame(interactions)
        
        # ç·¨ç¢¼å­¸ç”Ÿå’Œèª²ç¨‹ID
        self.interactions_df['student_idx'] = self.student_encoder.fit_transform(
            self.interactions_df['student_id']
        )
        self.interactions_df['course_idx'] = self.course_encoder.fit_transform(
            self.interactions_df['course_code']
        )
        
        # å‰µå»ºäº¤äº’çŸ©é™£
        n_students = len(self.student_encoder.classes_)
        n_courses = len(self.course_encoder.classes_)
        
        self.interaction_matrix = np.zeros((n_students, n_courses))
        for _, row in self.interactions_df.iterrows():
            self.interaction_matrix[int(row['student_idx']), int(row['course_idx'])] = row['rating']
            
    def _process_course_features(self):
        # 1. æ–‡å­—ç‰¹å¾µ â†¦ SBERT
        texts = (
            self.course_data['èª²ç¨‹åç¨±'].fillna('') + ' ' +
            self.course_data['èª²ç¨‹æè¿°'].fillna('')
        ).tolist()                         # list[str]
        with torch.no_grad():
            embeddings = sbert_model.encode(texts, convert_to_numpy=True, show_progress_bar=True)
            # embeddings.shape = (n_courses, 768)

        # 2. æ•¸å€¼ç‰¹å¾µç…§èˆŠ
        num_feats = []
        for _, c in self.course_data.iterrows():
            num_feats.append([
                c['å­¸åˆ†'],
                1 if c['å¿…é¸ä¿®'] == 'å¿…ä¿®' else 0,
                1 if c['ä¸Šèª²æ–¹å¼'] == 'èª²å ‚æ•™å­¸' else 0
            ])
        num_feats = self.scaler.fit_transform(np.array(num_feats))

        # 3. ä¸²æ¥ (æˆ–åˆ†é–‹é¤µæ¨¡å‹éƒ½å¯)
        self.course_content_features = np.hstack([embeddings, num_feats])

            
    def _process_student_features(self):
        """è™•ç†å­¸ç”Ÿç‰¹å¾µ"""
        student_features = []
        for _, student in self.student_data.iterrows():
            features = [
                student['grade_level'],
                student['gpa'],
                student['total_credits'],
                len(student['passed_courses'])
            ]
            student_features.append(features)
            
        self.student_features = np.array(student_features)
        self.student_features = self.scaler.fit_transform(self.student_features)


class CollaborativeFilteringModel(nn.Module):
    """å”åŒéæ¿¾ç¥ç¶“ç¶²çµ¡æ¨¡å‹"""
    
    def __init__(self, n_students, n_courses, embedding_dim=64, hidden_dims=[128, 64]):
        super(CollaborativeFilteringModel, self).__init__()
        
        # åµŒå…¥å±¤
        self.student_embedding = nn.Embedding(n_students, embedding_dim)
        self.course_embedding = nn.Embedding(n_courses, embedding_dim)
        
        # å…¨é€£æ¥å±¤
        layers = []
        input_dim = embedding_dim * 2
        
        for hidden_dim in hidden_dims:
            layers.extend([
                nn.Linear(input_dim, hidden_dim),
                nn.ReLU(),
                nn.Dropout(0.2)
            ])
            input_dim = hidden_dim
            
        layers.append(nn.Linear(input_dim, 1))
        layers.append(nn.Sigmoid())
        
        self.mlp = nn.Sequential(*layers)
        
    def forward(self, student_ids, course_ids):
        student_emb = self.student_embedding(student_ids)
        course_emb = self.course_embedding(course_ids)
        
        # é€£æ¥åµŒå…¥å‘é‡
        x = torch.cat([student_emb, course_emb], dim=1)
        output = self.mlp(x)
        
        return output.squeeze(1)


class ContentBasedModel(nn.Module):
    """åŸºæ–¼å…§å®¹çš„ç¥ç¶“ç¶²çµ¡æ¨¡å‹"""
    
    def __init__(self, student_feature_dim, course_feature_dim, hidden_dims=[128, 64]):
        super(ContentBasedModel, self).__init__()
        
        # å­¸ç”Ÿç‰¹å¾µç·¨ç¢¼å™¨
        self.student_encoder = nn.Sequential(
            nn.Linear(student_feature_dim, 32),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
        
        # èª²ç¨‹ç‰¹å¾µç·¨ç¢¼å™¨
        self.course_encoder = nn.Sequential(
            nn.Linear(course_feature_dim, 32),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
        
        # ç›¸ä¼¼åº¦è¨ˆç®—
        layers = []
        input_dim = 64  # 32 + 32
        
        for hidden_dim in hidden_dims:
            layers.extend([
                nn.Linear(input_dim, hidden_dim),
                nn.ReLU(),
                nn.Dropout(0.2)
            ])
            input_dim = hidden_dim
            
        layers.append(nn.Linear(input_dim, 1))
        layers.append(nn.Sigmoid())
        
        self.mlp = nn.Sequential(*layers)
        
    def forward(self, student_features, course_features):
        student_encoded = self.student_encoder(student_features)
        course_encoded = self.course_encoder(course_features)
        
        # é€£æ¥ç‰¹å¾µ
        x = torch.cat([student_encoded, course_encoded], dim=1)
        output = self.mlp(x)
        
        return output.squeeze(1)


class HybridModel(nn.Module):
    """æ··åˆæ¨è–¦æ¨¡å‹"""
    
    def __init__(self, collaborative_model, content_model, fusion_dim=32):
        super(HybridModel, self).__init__()
        
        self.collaborative_model = collaborative_model
        self.content_model = content_model
        
        # èåˆå±¤
        self.fusion_layer = nn.Sequential(
            nn.Linear(2, fusion_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(fusion_dim, 1),
            nn.Sigmoid()
        )
        
        # å¯å­¸ç¿’çš„æ¬Šé‡
        self.cf_weight = nn.Parameter(torch.tensor(0.5))
        self.cb_weight = nn.Parameter(torch.tensor(0.5))
        
    def forward(self, student_ids, course_ids, student_features, course_features):
        # å”åŒéæ¿¾é æ¸¬
        cf_output = self.collaborative_model(student_ids, course_ids)
        
        # å…§å®¹éæ¿¾é æ¸¬
        cb_output = self.content_model(student_features, course_features)
        
        # åŠ æ¬Šèåˆ
        weights = torch.softmax(torch.stack([self.cf_weight, self.cb_weight]), dim=0)
        weighted_output = weights[0] * cf_output + weights[1] * cb_output
        
        # é€²ä¸€æ­¥èåˆ
        fusion_input = torch.stack([cf_output, cb_output], dim=1)
        final_output = self.fusion_layer(fusion_input)
        
        # çµ„åˆæœ€çµ‚è¼¸å‡º
        return 0.7 * weighted_output + 0.3 * final_output.squeeze(1)


def train_model(model, train_loader, criterion, optimizer, epochs=10000):
    """è¨“ç·´æ¨¡å‹"""
    model.train()
    losses = []
    
    for epoch in range(epochs):
        epoch_loss = 0
        for batch in train_loader:
            optimizer.zero_grad()
            
            student_ids, course_ids, student_features, course_features, ratings = batch
            
            predictions = model(student_ids, course_ids, student_features, course_features)
            loss = criterion(predictions, ratings.float())
            
            loss.backward()
            optimizer.step()
            
            epoch_loss += loss.item()
            
        avg_loss = epoch_loss / len(train_loader)
        losses.append(avg_loss)
        
        if epoch % 20 == 0:
            print(f'Epoch {epoch}, Loss: {avg_loss:.4f}')
            
    return losses


def get_recommendations(model, student_id, rec_sys, top_k=10):
    model.eval()
    with torch.no_grad():
        # 1. å–å¾—å­¸ç”Ÿç´¢å¼•èˆ‡ç‰¹å¾µ
        if student_id not in rec_sys.student_encoder.classes_:
            return []

        sid = rec_sys.student_encoder.transform([student_id])[0]
        stu_feat = torch.FloatTensor(rec_sys.student_features[sid:sid+1])

        # 2. å·²ä¿®èª²èˆ‡ã€Œå¿…ä¿®ã€èª²ç¨‹æ¸…å–®
        taken = set(rec_sys.student_data.loc[
            rec_sys.student_data['student_id'] == student_id, 'passed_courses'
        ].iloc[0])

        # å…ˆæŠŠå¿…ä¿®èª²ç¨‹ç·¨ç¢¼æˆ setï¼ŒåŠ é€ŸæŸ¥è©¢
        required_set = set(
            rec_sys.course_data.loc[rec_sys.course_data['å¿…é¸ä¿®'] == 'å¿…ä¿®', 'èª²ç¨‹ç·¨ç¢¼']
        )

        recs = []
        for cidx, ccode in enumerate(rec_sys.course_encoder.classes_):
            # éæ¿¾ï¼šå·²ä¿®èª² or å¿…ä¿®
            if ccode in taken or ccode in required_set:
                continue

            course_feat = torch.FloatTensor(
                rec_sys.course_content_features[cidx:cidx+1]
            )
            score = model(
                torch.LongTensor([sid]),
                torch.LongTensor([cidx]),
                stu_feat,
                course_feat
            )
            recs.append((ccode, float(score)))

        # 3. ä¾åˆ†æ•¸æ’åºå– Top-k
        recs.sort(key=lambda x: x[1], reverse=True)
        return recs[:top_k]
    
def main():
    rec_system = HybridRecommendationSystem()
    rec_system.load_data('èª²ç¨‹è³‡æ–™_20250604_215356.csv', 'æ¨¡æ“¬å­¸ç”Ÿç¸½çµè³‡æ–™.csv')
    rec_system.preprocess_data()

    n_students = len(rec_system.student_encoder.classes_)
    n_courses  = len(rec_system.course_encoder.classes_)

    cf_model = CollaborativeFilteringModel(n_students, n_courses)
    cb_model = ContentBasedModel(
        rec_system.student_features.shape[1],
        rec_system.course_content_features.shape[1]
    )
    hybrid_model = HybridModel(cf_model, cb_model)

    # === å»º DataLoader ===
    train_dataset = InteractionDataset(rec_system)
    train_loader  = DataLoader(train_dataset, batch_size=512, shuffle=True)

    # === è¨“ç·´ ===
    criterion  = nn.BCELoss()
    optimizer  = optim.Adam(hybrid_model.parameters(), lr=1e-3)
    train_model(hybrid_model, train_loader, criterion, optimizer, epochs=5)

    # === å‡è£ç¬¬ä¸€ç­†å­¸ç”Ÿå°±æ˜¯ã€Œä½ ã€ ===
    first_student_id = rec_system.student_data.iloc[0]['student_id']
    top_recs = get_recommendations(hybrid_model, first_student_id, rec_system, top_k=10)

    print(f"\nğŸ“ é‡å°å­¸ç”Ÿ {first_student_id} æ¨è–¦èª²ç¨‹ï¼š")
    for rank, (code, score) in enumerate(top_recs, 1):
        name = rec_system.course_data.loc[
            rec_system.course_data['èª²ç¨‹ç·¨ç¢¼'] == code, 'èª²ç¨‹åç¨±'
        ].values[0]
        print(f"{rank:2d}. {code} {name:<20} â–¶ é æ¸¬åˆ†æ•¸ {score:.3f}")

    return rec_system, hybrid_model

if __name__ == "__main__":
    rec_system, model = main()

